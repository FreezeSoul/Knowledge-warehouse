# 00-集群环境准备

### 主机环境

节点配置：

|  资源   |  配置   |
| --- | --- |
| 节点数  | 4                                              |
| 操作系统 | CentOS Linux release 7.4.1708 (Core)           |
| CPU  | Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz 6核12线程 |
| 内存   | 16GB                                           |

### 软件环境
**注：** CDH5的所有软件可以在此下载：[http://archive.cloudera.com/cdh5/cdh/5/](http://archive.cloudera.com/cdh5/cdh/5/)

<table><colgroup><col><col><col></colgroup><tbody><tr><th>软件</th><th>版本</th><th>下载地址</th></tr><tr><td>jdk</td><td>jdk-8u172-linux-x64</td><td><a rel="nofollow" href="http://download.oracle.com/otn-pub/java/jdk/8u172-b11/a58eab1ec242421181065cdc37240b08/jdk-8u172-linux-x64.tar.gz">点击下载</a></td></tr><tr><td>hadoop</td><td>hadoop-2.6.0-cdh5.14.2</td><td><a rel="nofollow" href="http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.14.2.tar.gz">点击下载</a></td></tr><tr><td>zookeeeper</td><td>zookeeper-3.4.5-cdh5.14.2</td><td><a rel="nofollow" href="http://archive.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.14.2.tar.gz">点击下载</a></td></tr><tr><td>hbase</td><td>hbase-1.2.0-cdh5.14.2</td><td><a rel="nofollow" href="http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.14.2.tar.gz">点击下载</a></td></tr><tr><td>hive</td><td>hive-1.1.0-cdh5.14.2</td><td><a rel="nofollow" href="http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.14.2.tar.gz">点击下载</a></td></tr><tr><td>kylin</td><td>apache-kylin-2.4.0-bin-cdh57</td><td><a rel="nofollow" href="http://mirrors.hust.edu.cn/apache/kylin/apache-kylin-2.4.0/apache-kylin-2.4.0-bin-cdh57.tar.gz">点击下载</a></td></tr><tr><td>spark on yarn</td><td>spark-2.3.1-bin-hadoop2.6</td><td><a rel="nofollow" href="https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.6.tgz">点击下载</a></td></tr><tr><td>kafka</td><td>kafka_2.12-1.1.0</td><td><a rel="nofollow" href="http://mirrors.hust.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgz">点击下载</a></td></tr><tr><td>kafka-manager</td><td>kafka-manager-1.3.3.17</td><td><a rel="nofollow" href="https://github.com/yahoo/kafka-manager/archive/1.3.3.17.tar.gz">源码下载</a></td></tr></tbody></table>

kafka-manager官方只提供源码下载，下载后编译：sbt clean dist，此编译需要x翻XX墙x才能完成，没有条件的话可以下载网友编译好的低一点的版本：[kafka-manager-1.3.3.4](https://pan.baidu.com/s/1miDMuyG)


### 主机规划

5个节点角色规划如下：

<table><colgroup><col><col><col><col><col></colgroup><tbody><tr><th>主机名</th><th>pypycdhnode1</th><th>pypycdhnode2</th><th>pypycdhnode3</th><th>pypycdhnode4</th></tr><tr><td>IP</td><td>192.168.0.158</td><td>192.168.0.159</td><td>192.168.0.160</td><td>192.168.0.161</td></tr><tr><td>namenode</td><td>yes</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>dataNode</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>resourcemanager</td><td>yes</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>nodemanager</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>journalnode</td><td>no</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>zookeeper</td><td>no</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>hmaster(hbase)</td><td>yes</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>regionserver(hbase)</td><td>no</td><td>no</td><td>yes</td><td>yes</td></tr><tr><td>hive(hiveserver2)</td><td>yes</td><td>yes</td><td>no</td><td>no</td></tr><tr><td>mysql</td><td>no</td><td>no</td><td>no</td><td>yes</td></tr><tr><td>kafka</td><td>no</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>kafka-manager</td><td>no</td><td>no</td><td>yes</td><td>no</td></tr><tr><td>kylin</td><td>yes</td><td>no</td><td>no</td><td>no</td></tr><tr><td>spark on yarn</td><td>no</td><td>no</td><td>yes</td><td>no</td></tr></tbody></table>

**注：** Journalnode和ZooKeeper保持奇数个，如果需要高可用则不少于 3 个节点。具体原因，以后详叙。

### 主机安装前准备

1. 关闭所有节点的 `SELinux`

```
sed -i 's/^SELINUX=.*$/SELINUX=disabled/g' /etc/selinux/config
setenforce 0
```

1. 关闭所有节点防火墙 `firewalld` or `iptables`  

```
systemctl disable firewalld;
systemctl stop firewalld;
systemctl disable iptables;
systemctl stop iptables;
```

1. 开启所有节点时间同步 `ntpdate`

```
echo "*/5 * * * * /usr/sbin/ntpdate asia.pool.ntp.org | logger -t NTP" >> /var/spool/cron/root
```

1. 设置所有节点语言编码以及时区

```
echo 'export TZ=Asia/Shanghai' >> /etc/profile
echo 'export LANG=en_US.UTF-8' >> /etc/profile
. /etc/profile
```

1. 所有节点添加hadoop用户

```

useradd -m hadoop
echo 'hadoop' | passwd --stdin hadoop
# 设置PS1
su - hadoop
echo 'export PS1="\u@\h:\$PWD>"' >> ~/.bash_profile
echo "alias mv='mv -i'
alias rm='rm -i'" >> ~/.bash_profile
. ~/.bash_profile
exit
mkdir -p /application/hadoop
mv /application/hadoop /application
```

编辑 /etc/passwd 修改 hadoop 用户家目录为 `/application/hadoop`

1. 所有主机添加hosts文件 `vi /etc/hosts`,添加以下内容：

```
192.168.0.158 pypycdhnode1
192.168.0.159 pypycdhnode2
192.168.0.160 pypycdhnode3
192.168.0.161 pypycdhnode4
```

1. 设置hadoop用户之间免密登录   
   首先在pypycdhnode1主机生成秘钥

```
su - hadoop
ssh-keygen -t rsa # 一直回车即可生成hadoop用户的公钥和私钥
cd .ssh
vi id_rsa.pub # 去掉公钥末尾的 账号@主机名 : hadoop@pypycdhnode1
cat id_rsa.pub > authorized_keys
chmod 600 authorized_keys
```

压缩.ssh文件夹

```
su - hadoop
zip -r ssh.zip .ssh
```

随后分发ssh.zip到pypycdhnode2-4主机hadoop用户家目录解压即完成免密登录

1. 主机内核参数优化以及最大文件打开数、最大进程数等参数优化   
   不同主机优化参数有可能不一样，故这里不作出具体优化方法，但如果Hadoop环境用于正式生产，必须优化，linux默认参数可能会导致hadoop集群性能低下。   

2. datanode节点（pypycdhnode1-4）创建hdfs数据目录/chunk1，授权给hadoop用户

```
mkdir /application/chunk1
ln -sf /application/chunk1 /
chown -R hadoop. /application/chunk1
chown -R hadoop. /chunk1
```

**注：** 以上操作需要使用 `root` 用户，到目前为止操作系统环境已经准备完成，以下开始正式安装，后面的操作如果不做特殊说明均使用 `hadoop` 用户

### 安装jdk1.8

所有节点都需要安装，安装方式都一样   
解压 `jdk-8u172-linux-x64.tar.gz`

```
tar zxvf jdk-8u172-linux-x64.tar.gz
mkdir -p /application/hadoop/app
mv jdk-8u172-linux-x64 /application/hadoop/app/jdk
rm -f jdk-8u172-linux-x64.tar.gz
```

配置环境变量   
`vi ~/.bash_profile` 添加以下内容：

```
#java
export JAVA_HOME=/application/hadoop/app/jdk
export CLASSPATH=.:$JAVA_HOME/lib:$CLASSPATH
export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin
```

加载环境变量

```
. ~/.bash_profile
```

查看是否安装成功 `java -version`

```
java version "1.8.0_172"
Java(TM) SE Runtime Environment (build 1.8.0_172-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode)
```
